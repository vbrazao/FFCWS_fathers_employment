---
title: "Father's Analysis - Multiverse report"
format: html
editor: visual
execute:
  echo: false
bibliography: references.bib
csl: apa.csl
---

```{r}
#| warning: false
#| message: false

# packages ----------------------------------------------------------------
packages <- c("tidyverse", "here", "rempsyc", "cowplot")
groundhog_day <- "2024-04-22"

# (install and) load package versions available on the specified day to try
# to ensure reproducibility

library(groundhog)

groundhog::meta.groundhog(groundhog_day)

groundhog::groundhog.library(pkg = packages, date = groundhog_day)
```

```{r}
comps_results <- readRDS(here::here("02_analysis-codes", "outputs", "multiverse_comps_results.RDS")) |> 
  dplyr::mutate(
    significant = case_when(
      p.value < .05 ~ "Yes",
      p.value >= .05 ~ "No"
    ) |> factor()
  )

m_params <- readRDS(here::here("02_analysis-codes", "outputs", "multiverse_parameters.RDS"))

# functions

# to create the table
make_table <- function(results, only.sig = FALSE, outcome.omit = FALSE){
  
  if(only.sig){
    results <- results |> 
    dplyr::filter(
      p.value < .05
    )
  }
  
  if(outcome.omit){
    results <- results |> 
      dplyr::select(
      names(m_params), -outcome,
      estimate, p.value
    )
  } else {
    results <- results |> 
      dplyr::select(
      names(m_params),
      estimate, p.value
    )
  }
  
  tab <- results |> 
    dplyr::rename_with(
      .fn = ~ paste0("Specification option.", .x),
      .cols = -c(estimate, p.value)
    ) 
  
  tab %>% 
    rempsyc::nice_table(
      .,
      note = "* p < .05, ** p < .01, *** p < .001",
      separate.header = TRUE, italics = seq(.)
    )
}

# to create the specifications plots
make_spec_plot <- function(results, outcome.omit = TRUE){
  
  if(outcome.omit){
    results <- results |>
      dplyr::select(.universe, all_of(names(m_params)), significant, -outcome) |> 
      tidyr::pivot_longer(cols = -c(.universe, significant), names_to = "parameter_name", values_to =  "parameter_option") |> 
      dplyr::select( .universe, parameter_name, parameter_option, significant) |> 
      dplyr::filter(parameter_name != "outcome") |> 
      dplyr::mutate(
        parameter_name = factor(parameter_name) |> 
          forcats::fct_relevel("covariates", "weights", "proportion", "missing" )
      ) 
  } else {
    results <- results |>
      dplyr::select(.universe, all_of(names(m_params)), significant) |> 
      tidyr::pivot_longer(cols = -c(.universe, significant), names_to = "parameter_name", values_to =  "parameter_option") |> 
      dplyr::select( .universe, parameter_name, parameter_option, significant) |> 
      dplyr::mutate(
        parameter_name = factor(parameter_name) |> 
          forcats::fct_relevel("covariates", "weights", "proportion", "missing" )
      )     
  }
  
  plot <- results |> 
    ggplot() +
    geom_point( aes(x = .universe, y = parameter_option, color = significant), size = 0.5 ) +
    labs( x = "universe #", y = "specification option") + 
    facet_grid(parameter_name ~ ., space="free_y", scales="free_y", switch="y") +
    coord_cartesian(xlim = c(1, max(results$.universe)))  +
    scale_color_viridis_d(drop = FALSE, option = "plasma", end = .5) + 
    theme(
      strip.background = element_rect(fill = NA, colour = NA),
      strip.text.y = element_blank(), 
      legend.position = "none"
        )
  
  return(plot)
}

# to create the results plots 
make_res_plot <- function(results){
  results |> 
    ggplot(aes(x = .universe, y = estimate, ymax = conf.high, ymin = conf.low, color = significant)) +
    geom_point() +
    geom_errorbar() +
    geom_hline(yintercept = 0, linetype = "dashed", linewidth = 0.25) +
    labs(
      x = "",
    ) +
    scale_color_viridis_d(drop = FALSE, option = "plasma", end = .5) +
    coord_cartesian(xlim = c(1, max(results$.universe))) +
    theme(
      axis.text.x=element_blank(), #remove x axis labels
      axis.ticks.x=element_blank()
    )
}

# to create the two panel plots
make_plot <- function(results, ...){
  plot <- cowplot::plot_grid(
    make_res_plot(results), 
    make_spec_plot(results, ...), 
    axis = "bltr",  align = "v", ncol = 1, 
    rel_heights = c(1, 1)
  )
  
  return(plot)
}

```

# Multiverse results - Visualizations

## Effect of Race on Employment (B - W)

```{r}
results_emp_race <- comps_results |> 
  dplyr::filter(
    comp == "emp_race",
    outcome == "total",
    proportion != "binomial"
  ) |> 
  dplyr::mutate(
    .universe = 1:16
  )
```

```{r}
#| label: fig-emp-race
#| fig-cap: "Effect of Race on Employment by Specification"
cowplot::plot_grid(
  make_res_plot(results_emp_race), 
  make_spec_plot(results_emp_race), 
  axis = "bltr",  align = "v", ncol = 1, 
  rel_heights = c(1, 1)
)
```

Irrespective of our specification, we find a negative effect of race, meaning that black men are less likely to be employed. Analyses that adjust for covariates find a smaller effect of race on employment, indicating that some of the difference in employment rates can be accounted for by the downstream effects of race on the other covariates in the model. Comparing weighted and unweighted models, we find very similar estimates but slightly larger uncertainty for the unweighted models, suggesting that weights are not necessary to reduce the bias of our estimates in this instance.

Specifications for which there is a significant effect (all of them):

```{r}
#| label: tbl-emp-race-sig
#| tbl-cap: "Specifications with a significant effect of race on employment"

make_table(results_emp_race, only.sig = TRUE, outcome.omit = TRUE)
```

## Hypothesis 1: Effect of race on IPV (Black - White)

```{r}
results_ipv_race <- comps_results |> 
  dplyr::filter(comp == "ipv_race") |> 
  dplyr::arrange(estimate) %>% 
  dplyr::mutate(.universe = 1:nrow(.))
```

```{r}
#| label: fig-ipv-race
#| fig-cap: "Effect of Race on IPV by Specification"

make_plot(results_ipv_race, outcome.omit = FALSE)
```

The graph (and table below) reveal that there is some variability in the estimated effect, but all signficant effects are in the same direction: women partnered with Black men report higher levels of IPV.

Specifications for which there is a significant effect:

```{r}
#| label: tbl-ipv-race-sig
#| tbl-cap: "Specifications with a significant effect of race on IPV"

make_table(results_ipv_race, only.sig = TRUE, outcome.omit = FALSE)
```

### Total IPV

```{r}
results_ipv_race_total <- comps_results |> 
  dplyr::filter(comp == "ipv_race", outcome == "total") %>% 
  dplyr::mutate(.universe = 1:nrow(.))
```

```{r}
#| label: fig-total-ipv-race
#| fig-cap: "Effect of Race on total IPV by Specification"

make_plot(results_ipv_race_total, outcome.omit = TRUE)
```

Considering total IPV, all estimated effects are positive (women partnered with Black men report higher IPV), and almost half the estimates are statistically significant. Covariate-adjusted models generally produce smaller estimates, indicating that our covariates account for some of the effects of race on IPV. Weighted models produce similar estimates to the equivalent unweighted models, but the confidence intervals are larger. Whether we use only complete cases or impute missing values doesn't make a noticeable difference in our estimates. Estimates are very similar comparing binomial and linear (continuous) models, whereas models run on a binarized IPV measure show markedly larger estimates and larger uncertainty over all.

### Emotional IPV
```{r}
results_ipv_race_emotional <- comps_results |> 
  dplyr::filter(comp == "ipv_race", outcome == "emotional") %>% 
  dplyr::mutate(.universe = 1:nrow(.))
```

```{r}
#| label: fig-emotional-ipv-race
#| fig-cap: "Effect of Race on emotional IPV by Specification"

make_plot(results_ipv_race_emotional, outcome.omit = TRUE)
```
Considering emotional IPV, all estimated effects are positive (women partnered with Black men report higher IPV), and more than half the estimates are statistically significant. Covariate-adjusted models generally produce smaller estimates, indicating that our covariates account for some of the effects of race on IPV. Weighted models produce similar estimates to the equivalent unweighted models, but the confidence intervals are larger --- interestingly, estimates are always slightly larger for unweighted models that treat the outcome as linear or binomial compared to the same model with weights, while they are always slightly smaller for unweighted models that have a binarized outcome compared to the same model with weights. Whether we use only complete cases or impute missing values doesn't make a noticeable difference in our estimates. Estimates are very similar comparing binomial and linear (continuous) models, whereas models run on a binarized IPV measure show markedly larger estimates and larger uncertainty over all, and always produce statistically significant estimates.

### Controlling IPV
```{r}
results_ipv_race_controlling <- comps_results |> 
  dplyr::filter(comp == "ipv_race", outcome == "controlling") %>% 
  dplyr::mutate(.universe = 1:nrow(.))
```

```{r}
#| label: fig-controlling-ipv-race
#| fig-cap: "Effect of Race on controlling IPV by Specification"

make_plot(results_ipv_race_controlling, outcome.omit = TRUE)
```

Only four estimates of the effect of race on controlling IPV are significant, and all come from weighted models. 

## Physical IPV

## Total IPV

## Emotional IPV

## Controlling IPV

## Physical IPV
